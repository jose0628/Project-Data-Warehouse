## Project Summary
A Music Streaming Startup would like to get insight of the users activity on their music streaming app and get data insights to improve their services .
This project focuses on Extracting-Transforming-Loading (ETL) process and data modeling for the songs data in a star schema. 
The environment will set in Amazon Redshift and the project will allow to help as well to bring answers to business questions based on the data warehouse (i.e, most listened songs etc.).


## Datasets

### Song Dataset
The first dataset is a subset of real data from the [Million Song Dataset](http://millionsongdataset.com/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.

#### Single Song File Sample
```sql
{
    "num_songs": 1,
    "artist_id": "ARJIE2Y1187B994AB7",
    "artist_latitude": null,
    "artist_longitude": null,
    "artist_location": "",
    "artist_name": "Line Renaud",
    "song_id": "SOUPIRU12A6D4FA1E1",
    "title": "Der Kleine Dompfaff", 
    "duration": 152.92036, 
    "year": 0
}
```

### Log Dataset
The second dataset consists of log files in JSON format generated by this [Event Simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings.

#### Single Log File Sample

```sql
{
    "artist":null,
    "auth":"Logged In",
    "firstName":"Walter",
    "gender":"M",
    "itemInSession":0,
    "lastName":"Frye",
    "length":null,
    "level":"free",
    "location":"San Francisco-Oakland-Hayward, CA",
    "method":"GET",
    "page":"Home",
    "registration":1540919166796.0,
    "sessionId":38,
    "song":null,
    "status":200,
    "ts":1541105830796,
    "userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"",
    "userId":"39"
}
```

## Database Star Schema
The following star schema is proposed as a solution, and it contains the needed fact and dimension tables to have the data structured.

### Fact Table
1. songplays - records in log data associated with song plays i.e. records with page NextSong
    - songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent

### Dimension Tables
2. users - users in the app
    -user_id, first_name, last_name, gender, level

3. songs - songs in music database
    - song_id, title, artist_id, year, duration

4. artists - artists in music database
    - artist_id, name, location, latitude, longitude

5. time - timestamps of records in songplays broken down into specific units
    - start_time, hour, day, week, month, year, weekday

## Project Structure
    .
    ├── create_tables.py            # Drops and creates your tables.
    ├── etl.py                      # Reads and processes files from song_data and log_data and loads them into your tables.
    ├── sql_queries.py              # Contains all the sql queries for the project  
    └── dwh_template.cfg            # Rename it to dwh.cfg and add your Redshift Credentials.

## How to run
To Extract - Transform - Load the data in the database please follow the next steps in order:

1. rename **dwh_template.cfg** to **dwh.cfg** and fill all the needed credentials"
2. create_tables.py
3. etl.py

## Requirements

- It assumes that you have set up an AWS Redshift Cluster with a user under an IAM Role
- S3 service
